{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment 1 - Titanic Prediction Problem \n",
    "#Name : Shubham Deshmukh\n",
    "#Email : x2020gfv@stfx.ca\n",
    "#Student No. : 202006307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File Successfully Exported'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#------------------------Run this import section first------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "#-------------------------Specify the path of Data files------------------------\n",
    "\n",
    "url_train_datafile = 'train.csv'\n",
    "url_test_datafile = 'test.csv'\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#Importing dataset CSV files\n",
    "\n",
    "def importData(url_train_datafile, url_test_datafile):\n",
    "   \n",
    "    train_rawdata = pd.read_csv(url_train_datafile)\n",
    "    test_rawdata = pd.read_csv(url_test_datafile)\n",
    "\n",
    "    #Merging the two datasets and adding type column 1 = train , 0 = test and Survived = empty for unpredicted rows.\n",
    "    train_rawdata['Type'] = 1\n",
    "    test_rawdata['Type'] = 0\n",
    "    test_rawdata['Survived'] = ''\n",
    "\n",
    "    merged_train_test_data = train_rawdata.append(test_rawdata, ignore_index=False, verify_integrity=False, sort=None)\n",
    "    #print(merged_train_test_data)\n",
    "\n",
    "    return merged_train_test_data\n",
    "\n",
    "\n",
    "\n",
    "#Data Processing\n",
    "def processData (merged_train_test_data):\n",
    "\n",
    "    #*******Remove NA or Add new values to absent datas in merged dataset********\n",
    "    \n",
    "    #Replacing S=0, C=1, Q=2 & Filling value to empty cells in embarked by most frequent(mode) value. \n",
    "    merged_train_test_data[\"Embarked\"] = merged_train_test_data['Embarked'].replace(to_replace=['S', 'C','Q'], value=[0, 1, 2])\n",
    "    freq_embarked_value= merged_train_test_data['Embarked'].mode()\n",
    "    merged_train_test_data[\"Embarked\"] = merged_train_test_data['Embarked'].fillna(int(freq_embarked_value)).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    #Converting fare to int and replace NA with 0\n",
    "    merged_train_test_data['Fare'] = merged_train_test_data['Fare'].fillna( merged_train_test_data['Fare'].median()).astype(int) \n",
    "\n",
    "\n",
    "    # Remove Cabin letter from Cabin and dropping the other suffix values from it\n",
    "    cabinCode = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "\n",
    "    merged_train_test_data['Cabin'] = merged_train_test_data['Cabin'].fillna(\"U0\")\n",
    "    merged_train_test_data['Cabin'] = merged_train_test_data['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    merged_train_test_data['Cabin'] = merged_train_test_data['Cabin'].map(cabinCode)\n",
    "    merged_train_test_data['Cabin'] = merged_train_test_data['Cabin'].fillna(0).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Filling absent values of 'Age' Column in the entire data set using median based on Sex of the Passenger\n",
    "    merged_train_test_data[\"Age\"].fillna(merged_train_test_data.groupby('Sex')['Age'].transform(\"median\"), inplace=True)\n",
    "    \n",
    "    #print(merged_train_test_data['Age'])\n",
    "    \n",
    "    merged_train_test_data['Age'] = merged_train_test_data['Age'].astype(int)\n",
    "    merged_train_test_data.loc[ merged_train_test_data['Age'] <= 11, 'Age'] = 0\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Age'] > 11) & (merged_train_test_data['Age'] <= 18), 'Age'] = 1\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Age'] > 18) & (merged_train_test_data['Age'] <= 22), 'Age'] = 2\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Age'] > 22) & (merged_train_test_data['Age'] <= 27), 'Age'] = 3\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Age'] > 27) & (merged_train_test_data['Age'] <= 33), 'Age'] = 4\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Age'] > 33) & (merged_train_test_data['Age'] <= 40), 'Age'] = 5\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Age'] > 40) & (merged_train_test_data['Age'] <= 66), 'Age'] = 6\n",
    "    merged_train_test_data.loc[ merged_train_test_data['Age'] > 66, 'Age'] = 6\n",
    "    \n",
    "        \n",
    "    \n",
    "    #Transform Sex data as Male = 1 and Female = 0\n",
    "    merged_train_test_data['Sex'] = merged_train_test_data['Sex'].replace(to_replace=['male', 'female'], value=[1, 0])\n",
    "    \n",
    "\n",
    "    #Extracting Title out of name column and dropping the name column\n",
    "    titleCode = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"RareFemale\": 5, \"RareMale\": 6}\n",
    "\n",
    "    merged_train_test_data['Title'] = merged_train_test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # RareMale and RareFemale for unkown titles \n",
    "    merged_train_test_data['Title'] = merged_train_test_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr','Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    merged_train_test_data['Title'] = merged_train_test_data['Title'].replace(['Mlle','Ms'], 'Miss')\n",
    "    merged_train_test_data['Title'] = merged_train_test_data['Title'].replace('Mme', 'Mrs')\n",
    "    # RareMale for Rare title with Sex = Male and  RareFemale for Rare title with Sex = Male\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Title'] == 'Rare') &  (merged_train_test_data['Sex'] == 0),'Title'] = \"RareFemale\"\n",
    "    merged_train_test_data.loc[(merged_train_test_data['Title'] == 'Rare') &  (merged_train_test_data['Sex'] == 1),'Title'] = \"RareMale\"\n",
    "    \n",
    "    merged_train_test_data['Title'] = merged_train_test_data['Title'].map(titleCode)\n",
    "    merged_train_test_data = merged_train_test_data.drop(['Name'], axis=1)\n",
    "\n",
    "    \n",
    "    #Dropping the Ticket Column since it has random values which cannot be used to create any pattern\n",
    "    merged_train_test_data = merged_train_test_data.drop('Ticket',axis = 1)\n",
    "    \n",
    "\n",
    "    #*********************Creating New Features********************\n",
    "\n",
    "    #Add familysize column \n",
    "    merged_train_test_data['FamilySize'] = merged_train_test_data['SibSp'] + merged_train_test_data['Parch'] + 1\n",
    "\n",
    "\n",
    "    #Adding Fare per passanger \n",
    "    merged_train_test_data['FarePerPassanger'] = (merged_train_test_data['Fare']/(merged_train_test_data['FamilySize'])).astype(int)\n",
    "\n",
    "\n",
    "    return merged_train_test_data\n",
    "\n",
    "\n",
    "\n",
    "def divideData (merged_train_test_data):\n",
    "\n",
    "    #finaldata = merged_train_test_data\n",
    "    #Stating the Columns which are to be dropped \n",
    "    columns_toDrop = [ 'PassengerId','Survived','Type','Fare']\n",
    "\n",
    "    #Type = 1 means the tuples are training data with survival data \n",
    "    X_train = merged_train_test_data.loc[merged_train_test_data['Type'] == 1]\n",
    "    Y_train = X_train['Survived'].astype(int)\n",
    "    X_train = X_train.drop(columns_toDrop,axis=1)\n",
    "\n",
    "    #Type = 0 means the tuples are testing data without survival data\n",
    "    X_test = merged_train_test_data.loc[merged_train_test_data['Type'] == 0]\n",
    "    X_test = X_test.drop(columns_toDrop,axis=1)\n",
    "\n",
    "    return X_train,Y_train,X_test\n",
    "\n",
    "\n",
    "def applyModelRF(X_train,Y_train,X_test):\n",
    "\n",
    "    #Random Forest Classifier with Parameter\n",
    "   \n",
    "    rfc = RandomForestClassifier(bootstrap=False, criterion='entropy', max_features=1, min_samples_leaf=3, min_samples_split=10, random_state=42, n_estimators=1000).fit(X_train,Y_train)\n",
    "    Y_prediction = rfc.predict(X_test)\n",
    "    \n",
    "    #print(Y_prediction)\n",
    "    #print(\"RF Score : \",round(rfc.score(X_train, Y_train) * 100, 2))\n",
    "    #Find Importance of each column\n",
    "    #importance_Cols = pd.DataFrame({'feature':X_train.columns,'importance':np.round(rfc.feature_importances_,3)})\n",
    "    #importance_Cols = importance_Cols.sort_values('importance',ascending=False).set_index('feature')\n",
    "    #print(importance_Cols)\n",
    "    return Y_prediction\n",
    "\n",
    "\n",
    "def exportResultData(merged_train_test_data , Y_prediction,fileName):\n",
    "    passengerID = merged_train_test_data.loc[merged_train_test_data['Type'] == 0].PassengerId\n",
    "    predictedDF = pd.DataFrame(Y_prediction, columns = ['Survived'])\n",
    "    \n",
    "    finalresult = pd.concat([passengerID, predictedDF],axis=1)\n",
    "\n",
    "    finalresult.to_csv(fileName,index=False)\n",
    "    return 'File Successfully Exported'\n",
    "\n",
    "\n",
    "# ---------Main driver Funtion Call all the methods step by step with arguments to run the program.-----------------------------\n",
    "importedData =  importData(url_train_datafile, url_test_datafile)\n",
    "\n",
    "filteredData =  processData(importedData)\n",
    "\n",
    "X_train,Y_train,X_test = divideData(filteredData)\n",
    "\n",
    "predictedData =  applyModelRF(X_train,Y_train,X_test)\n",
    "\n",
    "exportResultData(importedData, predictedData, 'submission-2.csv')\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
